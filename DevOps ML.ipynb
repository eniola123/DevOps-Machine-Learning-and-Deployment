{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from flask import Flask, request, jsonify\n",
    "import traceback\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Qestion 1.\n",
    "\n",
    "# Use the training_data.csv to build and train a simple classification model. \n",
    "# The model needs to predict the target using the features f1, f2, and f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closser to 1 the better, The Accuracy score of the Model is 0.7138384470882906 \n",
      "Model dumped!\n",
      "Models columns dumped!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Modeling without paramter Tuning \n",
    "def DevOps_ML(df):\n",
    "    # Read Data\n",
    "    data = pd.read_csv(df)\n",
    "    # check missing value per each column\n",
    "    count_nan = len(data) - data.count()\n",
    "    #print(count_nan)\n",
    "    # Remove the missing value on feature column f3 and store back to Data\n",
    "    data = data.dropna()\n",
    "    data  =  pd.get_dummies(pd.DataFrame(data))\n",
    "    # Label And Features \n",
    "    labels = data['target']\n",
    "    features = data.drop('target', axis=1)\n",
    "    \n",
    "    # Split the data to train test and validation\n",
    "    train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=10)\n",
    "    model =  RF.fit(train, train_labels)\n",
    "    preds = RF.predict(test)\n",
    "    \n",
    "    Accuracy = accuracy_score(test_labels, preds)\n",
    "    print (\"The closser to 1 the better, The Accuracy score of the Model is {} \".format(Accuracy))\n",
    "    \n",
    "    joblib.dump(model, 'model.pkl')\n",
    "    print(\"Model dumped!\")\n",
    "    \n",
    "    # Saving the data columns from training\n",
    "    model_columns = list(features.columns)\n",
    "    joblib.dump(model_columns, 'model_columns.pkl')\n",
    "    print(\"Models columns dumped!\")\n",
    "    \n",
    "    return model \n",
    "        \n",
    "DevOps_ML('training_data.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model \n",
    "\n",
    "def model_saving(model):\n",
    "    \n",
    "    # Load the model that I just saved\n",
    "    RF = joblib.load(model)\n",
    "    return RF\n",
    "\n",
    "RF = model_saving('model.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SQLite database to log and monitor the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Database already exist'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Database if not exist\n",
    "\n",
    "def connectDB():\n",
    "    file = []\n",
    "    for filename in os.listdir():\n",
    "        file.append(filename)\n",
    "    if 'sqn.db' in file:\n",
    "        return 'Database already exist'\n",
    "    else:\n",
    "        conn = sqlite3.connect('sqn.db')\n",
    "        print (\"Opened database successfully\")\n",
    "    \n",
    "        # Create Tables\n",
    "        conn.execute('CREATE TABLE classification_request (id_request INTEGER PRIMARY KEY AUTOINCREMENT, request_timestamp TEXT NOT NULL, predicted_class INTEGER,response_status TEXT NOT NULL,error_message TEXT)')\n",
    "        conn.execute('CREATE TABLE classification_request_param (id_request INTEGER PRIMARY KEY AUTOINCREMENT,f1 TEXT NOT NULL,f2 TEXT NOT NULL,f3 TEXT NOT NULL, FOREIGN KEY(id_request) REFERENCES classification_request(id_request))')\n",
    "        print (\"Table created successfully\")\n",
    "        conn.close()\n",
    "\n",
    "connectDB()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Flask application with a REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Model columns loaded\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# Flask application with a REST API\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from sklearn.externals import joblib\n",
    "import logging\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from collections import Counter\n",
    "from statistics import mean \n",
    "\n",
    "\n",
    "# API definition\n",
    "app = Flask(__name__)\n",
    "\n",
    "# End point Classify\n",
    "@app.route('/classify', methods=['POST', 'GET'])\n",
    "def predict():\n",
    "    if rf:\n",
    "        try:\n",
    "            json_ = request.json\n",
    "            print(json_)\n",
    "            f1 = json_['f1']\n",
    "            f2 = json_['f2']\n",
    "            f3 = str(json_['f3'])\n",
    "            \n",
    "            \n",
    "            query = pd.get_dummies(pd.DataFrame(json_ , index=[0]))\n",
    "            query = query.reindex(columns=model_columns, fill_value=0)\n",
    "            prediction = rf.predict(query)\n",
    "            prediction_res = int(prediction[0])\n",
    "            \n",
    "            tz = pytz.timezone('Europe/Berlin')\n",
    "            request_timestamp = datetime.now(tz)\n",
    "            \n",
    "           # Request logged into Database if certain condition are met, as specified in the question\n",
    "            \n",
    "            if request.method == 'POST':\n",
    "                try:\n",
    "                    with sqlite3.connect(\"sqn.db\") as con:\n",
    "                        cur = con.cursor()\n",
    "                        print('consor connected')\n",
    "\n",
    "                        if type(f1) != float:\n",
    "                            response_status = \"ERROR\"\n",
    "                            error_message = \"f1 is not a float\"\n",
    "                            prediction_res = None\n",
    "                            cur.execute(\"INSERT INTO classification_request(request_timestamp, predicted_class,response_status,error_message ) VALUES(?,?,?,?)\",(request_timestamp, prediction_res, response_status,error_message) )\n",
    "                            cur.execute(\"INSERT INTO classification_request_param(f1,f2,f3) VALUES(?,?,?)\",(f1,f2,f3) )\n",
    "                            con.commit()\n",
    "                            msg = \"Record successfully added\"\n",
    "                            return jsonify({\"status\": \"ERROR\", \"error_message\": \"f1 is not a float.\"})\n",
    "                        \n",
    "                        elif type(f2) != float:\n",
    "                            print('skip2')\n",
    "                            response_status = \"ERROR\"\n",
    "                            error_message = \"f2 is not a float\"\n",
    "                            prediction_res = None\n",
    "                            cur.execute(\"INSERT INTO classification_request(request_timestamp, predicted_class,response_status,error_message ) VALUES(?,?,?,?)\",(request_timestamp, prediction_res, response_status,error_message) )\n",
    "                            cur.execute(\"INSERT INTO classification_request_param(f1,f2,f3) VALUES(?,?,?)\",(f1,f2,f3) )\n",
    "                            con.commit()\n",
    "                            msg = \"Record successfully added\"\n",
    "                            return jsonify({\"status\": \"ERROR\", \"error_message\": \"f2 is not a float.\"})\n",
    "                        \n",
    "                        elif type(f3) != str:\n",
    "                            print('skip3')\n",
    "                            response_status = \"ERROR\"\n",
    "                            error_message = \"f3 is not a string\"\n",
    "                            prediction_res = None\n",
    "                            cur.execute(\"INSERT INTO classification_request(request_timestamp, predicted_class,response_status,error_message ) VALUES(?,?,?,?)\",(request_timestamp, prediction_res, response_status,error_message) )\n",
    "                            cur.execute(\"INSERT INTO classification_request_param(f1,f2,f3) VALUES(?,?,?)\",(f1,f2,f3) )\n",
    "                            con.commit()\n",
    "                            msg = \"Record successfully added\"\n",
    "                            return jsonify({\"status\": \"ERROR\", \"error_message\": \"f3 is not a string.\"})\n",
    "\n",
    "                        lastrow = []\n",
    "                        def sql_fetch(con):\n",
    "                            cursorObj = con.cursor()\n",
    "                            cursorObj.execute('SELECT * FROM classification_request_param WHERE id_request = (SELECT MAX(id_request)-1 FROM classification_request_param)')\n",
    "                            rows = cursorObj.fetchall()\n",
    "                            for row in rows:\n",
    "                                for i in row:\n",
    "                                    lastrow.append(i)\n",
    "                        sql_fetch(con)\n",
    "                        \n",
    "                        #con.close()\n",
    "                        \n",
    "                        lastrow_com = lastrow[1:]\n",
    "                        jsonincome = []\n",
    "                        for j in json_:\n",
    "                            jsonincome.append(json_[j])\n",
    "                            \n",
    "                        lastrow_f = []\n",
    "                        for s in lastrow_com:\n",
    "                            try:\n",
    "                                lastrow_f.append(float(s))\n",
    "                            except ValueError:\n",
    "                                lastrow_f.append(s)\n",
    "                        \n",
    "                        if jsonincome == lastrow_f:\n",
    "                            response_status = \"WARNING\"\n",
    "                            error_message = None\n",
    "                            cur.execute(\"INSERT INTO classification_request(request_timestamp, predicted_class,response_status,error_message ) VALUES(?,?,?,?)\",(request_timestamp, prediction_res, response_status,error_message) )\n",
    "                            cur.execute(\"INSERT INTO classification_request_param(f1,f2,f3) VALUES(?,?,?)\",(f1,f2,f3) )\n",
    "                            con.commit()\n",
    "                            msg = \"Record successfully added\"\n",
    "                            return jsonify({\"predicted_class\": int(prediction), \"status\": \"WARNING\"})\n",
    "                            \n",
    "                        elif (type(f1) != float) or (type(f2) != float) or (type(f3) != str) == True :\n",
    "                            return \n",
    "                            \n",
    "                        else:\n",
    "                            response_status = \"OK\"\n",
    "                            error_message = None\n",
    "                            cur.execute(\"INSERT INTO classification_request(request_timestamp, predicted_class,response_status,error_message ) VALUES(?,?,?,?)\",(request_timestamp, prediction_res, response_status,error_message) )\n",
    "                            cur.execute(\"INSERT INTO classification_request_param(f1,f2,f3) VALUES(?,?,?)\",(f1,f2,f3) )\n",
    "                            con.commit()\n",
    "                            msg = \"Record successfully added\"\n",
    "                            return jsonify({'predicted_class': int(prediction),  \"status\": \"OK\" })\n",
    "                            \n",
    "                except:\n",
    "                    con.rollback()\n",
    "                    msg = \"error in insert operation\"\n",
    "                finally:\n",
    "                    print(msg)\n",
    "                    con.close()\n",
    "        except:\n",
    "            \n",
    "            return jsonify({'trace': traceback.format_exc()})\n",
    "\n",
    "        return 'Test with Postman'\n",
    "    \n",
    "        \n",
    "    else:\n",
    "        print ('Train the model first')\n",
    "        return ('No model here to use')\n",
    "    \n",
    "# End point /stats, return mean of f1, f2 and most frequent f3 \n",
    "@app.route('/stats', methods=['POST', 'GET'])\n",
    "def stat():\n",
    "    if rf:\n",
    "        try:\n",
    "            mean_f1_list = []\n",
    "            mean_f2_list = []\n",
    "            mostFrequent_f3_list = []\n",
    "            if request.method == 'GET':\n",
    "                try:\n",
    "                    with sqlite3.connect(\"sqn.db\") as con:\n",
    "                        cur = con.cursor()\n",
    "                        print('consor connected')\n",
    "                        cur.execute(\"\"\"SELECT c.id_request, cast(c.f1 as INT), cast(c.f2 as INT), c.f3\n",
    "                                    FROM classification_request_param c \n",
    "                                    INNER JOIN\n",
    "                                    classification_request p\n",
    "                                    ON c.id_request = p.id_request\n",
    "                                    WHERE  p.response_status = \"OK\" ; \"\"\")\n",
    "                        print('execute ok')\n",
    "                        rows = cur.fetchall()\n",
    "                        print('fetch ok')\n",
    "                        for row in rows:\n",
    "                            mean_f1_list.append(row[1])\n",
    "                            mean_f2_list.append(row[2])\n",
    "                            mostFrequent_f3_list.append(row[3])\n",
    "                    sql_fetch(con)\n",
    "                    print('fetch ok')\n",
    "                    mean_f1 =  mean(mean_f1_list)\n",
    "                    mean_f2 =  mean(mean_f2_list)\n",
    "            \n",
    "                    def most_frequent(List): \n",
    "                        occurence_count = Counter(List) \n",
    "                        return occurence_count.most_common(1)[0][0] \n",
    "                    f3_most_frequent = most_frequent(mostFrequent_f3_list)\n",
    "            \n",
    "                    print(mean_f1)\n",
    "                \n",
    "                except:\n",
    "                    con.rollback()\n",
    "                    msg = \"error in insert operation\"\n",
    "                finally:\n",
    "                    #print(msg)\n",
    "                    con.close()\n",
    "        \n",
    "        except:\n",
    "            return jsonify({'trace': traceback.format_exc()})\n",
    "        \n",
    "        print(mean_f1)\n",
    "        print(mean_f2)\n",
    "        print(f3_most_frequent)\n",
    "        \n",
    "        return jsonify({\"mean_f1\": mean_f1, \"mean_f2\": mean_f2, \"most_frequent_f3\": f3_most_frequent})\n",
    "    else:\n",
    "        print ('Train the model first')\n",
    "        return ('No model here to use')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        port = int(sys.argv[1]) # This is for a command-line input\n",
    "    except:\n",
    "        port = 1234 # If you don't provide any port the port will be set to 12345\n",
    "\n",
    "    rf = joblib.load(\"model.pkl\") # Load \"model.pkl\"\n",
    "    print ('Model loaded')\n",
    "    model_columns = joblib.load(\"model_columns.pkl\") # Load \"model_columns.pkl\"\n",
    "    print ('Model columns loaded')\n",
    "\n",
    "    app.run(port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
